{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a1c4915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Celda 0: imports básicos y semilla global ---\n",
    "\n",
    "import os, random\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"src\")  \n",
    "\n",
    "from config import (\n",
    "    block_size, embed_size, dropout, n_heads, n_layer,\n",
    "    eval_iters, batch_size, learn_rate, max_iters, eval_interval,\n",
    "    end_token, unknown_token\n",
    ")\n",
    "SEED = 42\n",
    "\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "629001f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The corpus has 142 unique tokens.\n",
      "SUCCESS\n"
     ]
    }
   ],
   "source": [
    "from preprocess import make_train_test\n",
    "\n",
    "make_train_test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e27e6a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño vocabulario: 142\n",
      "Tamaño train_data : torch.Size([1165])\n",
      "Tamaño valid_data : torch.Size([130])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([  7,  70,   2, 140,  39,   5, 126,   6,   4,  12,  53,  24,   2, 139,\n",
       "         61,   0,   4,  11,  70,  19,   2, 138, 121,  53,  24,   3, 139,  61,\n",
       "        102,   5,   0,   4,  10,  70,  13, 126,   2, 140, 105, 120,   6,   4,\n",
       "          8,  88,  84,   2, 114,   5,   3, 140])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Celda 2: cargar train/valid y vocabulario ---\n",
    "\n",
    "import json\n",
    "import torch\n",
    "\n",
    "train_data = torch.load(\"assets/output/train.pt\")\n",
    "valid_data = torch.load(\"assets/output/valid.pt\")\n",
    "\n",
    "with open(\"assets/output/vocab.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    vocab = json.loads(f.read())\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "print(f\"Tamaño vocabulario: {vocab_size}\")\n",
    "print(f\"Tamaño train_data : {train_data.shape}\")\n",
    "print(f\"Tamaño valid_data : {valid_data.shape}\")\n",
    "\n",
    "# mirar los primeros 50 índices de entrenamiento\n",
    "train_data[:50]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "062d7baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block_size: 32\n",
      "batch_size: 32\n",
      "Shape xb: torch.Size([32, 32])\n",
      "Shape yb: torch.Size([32, 32])\n",
      "Secuencia índices: tensor([ 21,   0,   4,  10, 139, 132,  13, 113, 129,  59,  40, 112,  57,   0,\n",
      "          4,   8, 139,  40,   5,   0])\n",
      "Secuencia tokens decodificada:\n",
      " ansias ! <END> Paul: ¡ va a ser un fin de semana fantástico ! <END> Anna: ¡ de <UNK> ! <END> Sandra: ¡ no puedo esperar por la cena y la noche\n"
     ]
    }
   ],
   "source": [
    "# --- Celda 3: utilidades de batching y encode/decode ---\n",
    "\n",
    "from utils import get_batch, encode, decode, estimate_loss\n",
    "\n",
    "print(\"block_size:\", block_size)\n",
    "print(\"batch_size:\", batch_size)\n",
    "\n",
    "# ejemplo rápido de batch\n",
    "xb, yb = get_batch(train_data)\n",
    "print(\"Shape xb:\", xb.shape)  # (batch_size, block_size)\n",
    "print(\"Shape yb:\", yb.shape)\n",
    "\n",
    "# ejemplo de decode de una ventana cualquiera\n",
    "sample = xb[0]\n",
    "print(\"Secuencia índices:\", sample[:20])\n",
    "print(\"Secuencia tokens decodificada:\\n\", decode(sample, vocab))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9392a903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTLanguageModel(\n",
      "  (token_embedding): Embedding(142, 256)\n",
      "  (pos_embedding): Embedding(32, 256)\n",
      "  (blocks): Sequential(\n",
      "    (0): Block(\n",
      "      (sa): MultiHeadAttention(\n",
      "        (heads): ModuleList(\n",
      "          (0-5): 6 x Head(\n",
      "            (key): Linear(in_features=256, out_features=42, bias=False)\n",
      "            (query): Linear(in_features=256, out_features=42, bias=False)\n",
      "            (value): Linear(in_features=256, out_features=42, bias=False)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (linear): Linear(in_features=252, out_features=256, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (ffwd): FeedFoward(\n",
      "        (net): Sequential(\n",
      "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "          (3): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (1): Block(\n",
      "      (sa): MultiHeadAttention(\n",
      "        (heads): ModuleList(\n",
      "          (0-5): 6 x Head(\n",
      "            (key): Linear(in_features=256, out_features=42, bias=False)\n",
      "            (query): Linear(in_features=256, out_features=42, bias=False)\n",
      "            (value): Linear(in_features=256, out_features=42, bias=False)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (linear): Linear(in_features=252, out_features=256, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (ffwd): FeedFoward(\n",
      "        (net): Sequential(\n",
      "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "          (3): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (2): Block(\n",
      "      (sa): MultiHeadAttention(\n",
      "        (heads): ModuleList(\n",
      "          (0-5): 6 x Head(\n",
      "            (key): Linear(in_features=256, out_features=42, bias=False)\n",
      "            (query): Linear(in_features=256, out_features=42, bias=False)\n",
      "            (value): Linear(in_features=256, out_features=42, bias=False)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (linear): Linear(in_features=252, out_features=256, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (ffwd): FeedFoward(\n",
      "        (net): Sequential(\n",
      "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "          (3): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (3): Block(\n",
      "      (sa): MultiHeadAttention(\n",
      "        (heads): ModuleList(\n",
      "          (0-5): 6 x Head(\n",
      "            (key): Linear(in_features=256, out_features=42, bias=False)\n",
      "            (query): Linear(in_features=256, out_features=42, bias=False)\n",
      "            (value): Linear(in_features=256, out_features=42, bias=False)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (linear): Linear(in_features=252, out_features=256, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (ffwd): FeedFoward(\n",
      "        (net): Sequential(\n",
      "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "          (3): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (4): Block(\n",
      "      (sa): MultiHeadAttention(\n",
      "        (heads): ModuleList(\n",
      "          (0-5): 6 x Head(\n",
      "            (key): Linear(in_features=256, out_features=42, bias=False)\n",
      "            (query): Linear(in_features=256, out_features=42, bias=False)\n",
      "            (value): Linear(in_features=256, out_features=42, bias=False)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (linear): Linear(in_features=252, out_features=256, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (ffwd): FeedFoward(\n",
      "        (net): Sequential(\n",
      "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "          (3): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (5): Block(\n",
      "      (sa): MultiHeadAttention(\n",
      "        (heads): ModuleList(\n",
      "          (0-5): 6 x Head(\n",
      "            (key): Linear(in_features=256, out_features=42, bias=False)\n",
      "            (query): Linear(in_features=256, out_features=42, bias=False)\n",
      "            (value): Linear(in_features=256, out_features=42, bias=False)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (linear): Linear(in_features=252, out_features=256, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (ffwd): FeedFoward(\n",
      "        (net): Sequential(\n",
      "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "          (3): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (ln_output): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "  (linear_output): Linear(in_features=256, out_features=142, bias=True)\n",
      ")\n",
      "\n",
      "Número total de parámetros: 4,790,926\n"
     ]
    }
   ],
   "source": [
    "# --- Celda 4: crear el modelo GPT ---\n",
    "\n",
    "from model import GPTLanguageModel\n",
    "\n",
    "model = GPTLanguageModel(vocab_size)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "# cuántos parámetros tiene\n",
    "n_params = sum(p.numel() for p in model.parameters())\n",
    "print(model)\n",
    "print(f\"\\nNúmero total de parámetros: {n_params:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2dceb11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.0003\n"
     ]
    }
   ],
   "source": [
    "# --- Celda 5: optimizador (AdamW) ---\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learn_rate)\n",
    "print(\"Learning rate:\", learn_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55ad6292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pérdidas iniciales: {'train': tensor(5.0562), 'valid': tensor(5.0316)}\n"
     ]
    }
   ],
   "source": [
    "# --- Celda 6: helper para evaluar pérdidas en train/valid ---\n",
    "\n",
    "def eval_train_valid(model, train_data, valid_data):\n",
    "    losses = {}\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        losses[\"train\"] = estimate_loss(model, train_data)\n",
    "        losses[\"valid\"] = estimate_loss(model, valid_data)\n",
    "    model.train()\n",
    "    return losses\n",
    "\n",
    "# prueba rápida (modelo recién inicializado)\n",
    "losses0 = eval_train_valid(model, train_data, valid_data)\n",
    "print(\"Pérdidas iniciales:\", losses0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "302e9a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:04:06 | step 0 | train loss 5.0565 | valid loss 5.0319\n",
      "21:06:41 | step 500 | train loss 0.1544 | valid loss 4.8930\n",
      "21:09:38 | step 1000 | train loss 0.1231 | valid loss 5.5764\n",
      "21:12:29 | step 1500 | train loss 0.1170 | valid loss 5.9692\n",
      "21:15:29 | step 2000 | train loss 0.1148 | valid loss 6.1883\n",
      "21:18:19 | step 2500 | train loss 0.1124 | valid loss 6.6059\n",
      "21:21:08 | step 3000 | train loss 0.1143 | valid loss 6.5490\n",
      "21:23:57 | step 3500 | train loss 0.1095 | valid loss 6.8801\n",
      "21:26:47 | step 4000 | train loss 0.1105 | valid loss 7.1285\n",
      "21:29:37 | step 4500 | train loss 0.1102 | valid loss 7.2325\n",
      "Entrenamiento terminado.\n"
     ]
    }
   ],
   "source": [
    "# --- Celda 7: entrenamiento principal ---\n",
    "\n",
    "from utils import current_time\n",
    "\n",
    "for step in range(max_iters):\n",
    "    # cada cierto número de pasos, evaluamos en train/valid\n",
    "    if step % eval_interval == 0:\n",
    "        losses = eval_train_valid(model, train_data, valid_data)\n",
    "        t = current_time()\n",
    "        print(f\"{t} | step {step} | \"\n",
    "              f\"train loss {losses['train']:.4f} | valid loss {losses['valid']:.4f}\")\n",
    "\n",
    "    # obtenemos un batch de entrenamiento\n",
    "    xb, yb = get_batch(train_data)\n",
    "    xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "\n",
    "    # forward + loss\n",
    "    logits, loss = model(xb, yb)\n",
    "\n",
    "    # backward + update\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(\"Entrenamiento terminado.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e76c5c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado en: assets/models/model_es.pt\n"
     ]
    }
   ],
   "source": [
    "# --- Celda 8: guardar modelo entrenado ---\n",
    "os.makedirs(\"assets/models\", exist_ok=True)\n",
    "model_path = \"assets/models/model_es.pt\"\n",
    "\n",
    "torch.save(model, model_path)\n",
    "print(f\"Modelo guardado en: {model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274f7c16",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "GPTLanguageModel.generate() got an unexpected keyword argument 'max_new_tokens'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# generamos hasta ver <END> o un máximo de 50 tokens\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 11\u001b[0m     out \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[0;32m     12\u001b[0m         idx\u001b[38;5;241m=\u001b[39mx0,\n\u001b[0;32m     13\u001b[0m         max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[0;32m     14\u001b[0m         end_token\u001b[38;5;241m=\u001b[39mend_token    \u001b[38;5;66;03m# el modelo deja de generar cuando ve este token\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     )\n\u001b[0;32m     17\u001b[0m generated \u001b[38;5;241m=\u001b[39m out[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# secuencia 1D\u001b[39;00m\n\u001b[0;32m     18\u001b[0m texto \u001b[38;5;241m=\u001b[39m decode(generated, vocab)\n",
      "\u001b[1;31mTypeError\u001b[0m: GPTLanguageModel.generate() got an unexpected keyword argument 'max_new_tokens'"
     ]
    }
   ],
   "source": [
    "# --- Celda 9: generación de texto en español (demo) ---\n",
    "\n",
    "from config import end_token\n",
    "\n",
    "# empezamos con un token de inicio sencillo: por ejemplo el nombre de un contacto o una palabra\n",
    "prompt_tokens = [\"Hola\", \":\"]\n",
    "x0 = encode(prompt_tokens, vocab).view(1, -1)  # (1, T)\n",
    "\n",
    "with torch.no_grad():\n",
    "    generated = model.generate(x0, vocab)  # <- sin kwargs extra\n",
    "\n",
    "texto = decode(generated, vocab)\n",
    "print(\"PROMPT :\", \" \".join(prompt_tokens))\n",
    "print(\"SALIDA :\", texto)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
